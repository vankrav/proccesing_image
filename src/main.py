import argparse
import os
import sys
import time
import types

import cv2
import numpy as np
from rembg import remove, new_session
from PIL import Image, ImageOps

try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: MediaPipe –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install mediapipe")


def fix_image_orientation(img: Image.Image) -> Image.Image:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ EXIF –¥–∞–Ω–Ω—ã—Ö.
    –ú–Ω–æ–≥–∏–µ –∫–∞–º–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ImageOps.exif_transpose –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
    """
    try:
        # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± (PIL 8.0+)
        img = ImageOps.exif_transpose(img)
    except (AttributeError, TypeError, ValueError):
        # –ï—Å–ª–∏ ImageOps.exif_transpose –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±
        try:
            if hasattr(img, '_getexif') and img._getexif() is not None:
                exif = img._getexif()
                orientation = exif.get(274)  # EXIF tag 274 = Orientation
                
                if orientation == 2:
                    img = img.transpose(Image.FLIP_LEFT_RIGHT)
                elif orientation == 3:
                    img = img.rotate(180, expand=True)
                elif orientation == 4:
                    img = img.transpose(Image.FLIP_TOP_BOTTOM)
                elif orientation == 5:
                    img = img.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)
                elif orientation == 6:
                    img = img.rotate(-90, expand=True)
                elif orientation == 7:
                    img = img.rotate(90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)
                elif orientation == 8:
                    img = img.rotate(90, expand=True)
        except (AttributeError, KeyError, TypeError):
            # –ï—Å–ª–∏ EXIF –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å
            pass
    
    return img


def normalize_exposure(img: Image.Image, debug: bool = False) -> Image.Image:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —ç–∫—Å–ø–æ–∑–∏—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—è—Ä–∫–æ—Å—Ç—å –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç CLAHE (Contrast Limited Adaptive Histogram Equalization) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
    –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏.
    """
    if img.mode != "RGB":
        img_rgb = img.convert("RGB")
    else:
        img_rgb = img.copy()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array –¥–ª—è OpenCV
    img_array = np.array(img_rgb)
    img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º CLAHE –∫ –∫–∞–Ω–∞–ª—É L (—è—Ä–∫–æ—Å—Ç—å) —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º clipLimit –¥–ª—è –±–æ–ª—å—à–µ–π —è—Ä–∫–æ—Å—Ç–∏
    clahe = cv2.createCLAHE(clipLimit=3.5, tileGridSize=(8, 8))
    img_cv[:, :, 0] = clahe.apply(img_cv[:, :, 0])
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ–º —è—Ä–∫–æ—Å—Ç—å (—É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–∞–Ω–∞–ª L –Ω–∞ 10-15%)
    l_channel = img_cv[:, :, 0].astype(np.float32)
    l_channel = l_channel * 1.15  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —è—Ä–∫–æ—Å—Ç—å –Ω–∞ 15%
    l_channel = np.clip(l_channel, 0, 255).astype(np.uint8)
    img_cv[:, :, 0] = l_channel
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ RGB
    img_normalized = cv2.cvtColor(img_cv, cv2.COLOR_LAB2RGB)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL Image
    result = Image.fromarray(img_normalized)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª, –µ—Å–ª–∏ –±—ã–ª
    if img.mode == "RGBA":
        result = result.convert("RGBA")
        alpha = img.split()[3]
        result.putalpha(alpha)
    
    if debug:
        print("üì∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ (CLAHE + –ø–æ–≤—ã—à–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ –Ω–∞ 15%)")
    
    return result


def load_image(path: str, debug_orientation: bool = False) -> Image.Image:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ RGBA —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.
    
    Args:
        path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        debug_orientation: –ï—Å–ª–∏ True, –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏
    """
    img = Image.open(path)
    original_size = img.size
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π
    img = fix_image_orientation(img)
    
    if debug_orientation and img.size != original_size:
        print(f"‚ö†Ô∏è –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—ã–ª–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {original_size} -> {img.size}")
    
    img = img.convert("RGBA")
    return img


def detect_face_mediapipe(img: Image.Image | np.ndarray, debug: bool = True, debug_file: str | None = None) -> dict | None:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –ª–∏—Ü–æ —Å –ø–æ–º–æ—â—å—é MediaPipe –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–º.
    
    Args:
        img: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ PIL Image –∏–ª–∏ numpy array (BGR/RGB)
        debug: –ï—Å–ª–∏ True, –≤—ã–≤–æ–¥–∏—Ç –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω—Å–æ–ª—å
        debug_file: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ª–∏—Ü–µ:
        - 'detected': bool - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏ –ª–∏—Ü–æ
        - 'face_count': int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ª–∏—Ü
        - 'landmarks': list - —Å–ø–∏—Å–æ–∫ landmarks (468 —Ç–æ—á–µ–∫ –¥–ª—è Face Mesh)
        - 'bounding_boxes': list - —Å–ø–∏—Å–æ–∫ bounding boxes –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞
        - 'face_landmarks_2d': list - 2D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã landmarks
        - 'face_landmarks_3d': list - 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã landmarks (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
        - 'face_blendshapes': list - blendshapes (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
        - 'face_geometry': dict - –≥–µ–æ–º–µ—Ç—Ä–∏—è –ª–∏—Ü–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
    """
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ (–≤ –∫–æ–Ω—Å–æ–ª—å –∏/–∏–ª–∏ —Ñ–∞–π–ª)
    debug_output = []
    def debug_print(*args, **kwargs):
        msg = ' '.join(str(a) for a in args)
        if debug:
            print(*args, **kwargs)
        if debug_file:
            debug_output.append(msg)
    
    if not MEDIAPIPE_AVAILABLE:
        if debug:
            debug_print("‚ùå MediaPipe –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞.")
        return None
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if isinstance(img, Image.Image):
        img_array = np.array(img.convert("RGB"))
        img_rgb = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    else:
        img_rgb = img.copy()
        if len(img_rgb.shape) == 4:  # RGBA
            img_rgb = cv2.cvtColor(img_rgb[:, :, :3], cv2.COLOR_BGRA2BGR)
        elif len(img_rgb.shape) == 3:
            if img_rgb.shape[2] == 4:  # RGBA
                img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGRA2BGR)
    
    h, w = img_rgb.shape[:2]
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if debug:
        debug_print("\n" + "="*60)
        debug_print("üìê –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ò")
        debug_print("="*60)
        debug_print(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {w} x {h} –ø–∏–∫—Å–µ–ª–µ–π")
        debug_print(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: {'–ü–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è' if h > w else '–ê–ª—å–±–æ–º–Ω–∞—è' if w > h else '–ö–≤–∞–¥—Ä–∞—Ç–Ω–∞—è'}")
        if isinstance(img, Image.Image):
            debug_print(f"–§–æ—Ä–º–∞—Ç: {img.format if hasattr(img, 'format') else 'N/A'}")
            debug_print(f"–†–µ–∂–∏–º: {img.mode if hasattr(img, 'mode') else 'N/A'}")
        debug_print("="*60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MediaPipe Face Detection –∏ Face Mesh
    mp_face_detection = mp.solutions.face_detection
    mp_face_mesh = mp.solutions.face_mesh
    mp_drawing = mp.solutions.drawing_utils
    mp_drawing_styles = mp.solutions.drawing_styles
    
    result = {
        'detected': False,
        'face_count': 0,
        'landmarks': [],
        'bounding_boxes': [],
        'face_landmarks_2d': [],
        'face_landmarks_3d': [],
        'face_blendshapes': [],
        'face_geometry': {},
        'image_size': {'width': w, 'height': h}
    }
    
    # Face Detection
    with mp_face_detection.FaceDetection(
        model_selection=1,  # 0 –¥–ª—è –±–ª–∏–∂–Ω–∏—Ö –ª–∏—Ü, 1 –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö
        min_detection_confidence=0.5
    ) as face_detection:
        detection_results = face_detection.process(cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB))
        
        if debug:
            debug_print("\n" + "="*60)
            debug_print("üîç MEDIAPIPE FACE DETECTION - –î–ï–ë–ê–ì –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
            debug_print("="*60)
        
        if detection_results.detections:
            result['face_count'] = len(detection_results.detections)
            result['detected'] = True
            
            if debug:
                debug_print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {result['face_count']}")
            
            for idx, detection in enumerate(detection_results.detections):
                # Bounding box
                bbox = detection.location_data.relative_bounding_box
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                
                bounding_box = {
                    'x': x,
                    'y': y,
                    'width': width,
                    'height': height,
                    'confidence': detection.score[0] if detection.score else 0.0
                }
                result['bounding_boxes'].append(bounding_box)
                
                if debug:
                    debug_print(f"\n--- –õ–∏—Ü–æ #{idx + 1} ---")
                    debug_print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (confidence): {detection.score[0]:.4f}" if detection.score else "  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: N/A")
                    debug_print(f"  Bounding Box:")
                    debug_print(f"    X: {x}, Y: {y}")
                    debug_print(f"    –®–∏—Ä–∏–Ω–∞: {width}, –í—ã—Å–æ—Ç–∞: {height}")
                    debug_print(f"    –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: x={bbox.xmin:.4f}, y={bbox.ymin:.4f}, w={bbox.width:.4f}, h={bbox.height:.4f}")
                
                # Key points (6 —Ç–æ—á–µ–∫: –≥–ª–∞–∑–∞, –Ω–æ—Å, —Ä–æ—Ç, —É—à–∏)
                if detection.location_data.relative_keypoints:
                    if debug:
                        debug_print(f"  –ö–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ (keypoints): {len(detection.location_data.relative_keypoints)}")
                    keypoints = []
                    for kp_idx, keypoint in enumerate(detection.location_data.relative_keypoints):
                        kp_x = int(keypoint.x * w)
                        kp_y = int(keypoint.y * h)
                        keypoints.append({
                            'x': kp_x,
                            'y': kp_y,
                            'relative_x': keypoint.x,
                            'relative_y': keypoint.y,
                            'name': ['right_eye', 'left_eye', 'nose_tip', 'mouth_center', 'right_ear', 'left_ear'][kp_idx] if kp_idx < 6 else f'point_{kp_idx}'
                        })
                        if debug:
                            debug_print(f"    {keypoints[-1]['name']}: ({kp_x}, {kp_y}) [–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ: ({keypoint.x:.4f}, {keypoint.y:.4f})]")
        else:
            if debug:
                debug_print("‚ùå –õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    
    # Face Mesh (468 landmarks)
    with mp_face_mesh.FaceMesh(
        static_image_mode=True,
        max_num_faces=5,
        refine_landmarks=True,  # –í–∫–ª—é—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ landmarks (468 -> 468)
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as face_mesh:
        mesh_results = face_mesh.process(cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB))
        
        if debug:
            debug_print("\n" + "-"*60)
            debug_print("üîç MEDIAPIPE FACE MESH - –î–ï–ë–ê–ì –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
            debug_print("-"*60)
        
        if mesh_results.multi_face_landmarks:
            if debug:
                debug_print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü –≤ mesh: {len(mesh_results.multi_face_landmarks)}")
            
            for face_idx, face_landmarks in enumerate(mesh_results.multi_face_landmarks):
                landmarks_2d = []
                landmarks_3d = []
                
                if debug:
                    debug_print(f"\n--- Face Mesh #{face_idx + 1} ---")
                    debug_print(f"  –í—Å–µ–≥–æ landmarks: {len(face_landmarks.landmark)}")
                
                for landmark_idx, landmark in enumerate(face_landmarks.landmark):
                    # 2D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
                    x_2d = int(landmark.x * w)
                    y_2d = int(landmark.y * h)
                    z_2d = landmark.z * w  # z –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –ø–æ —à–∏—Ä–∏–Ω–µ
                    
                    landmarks_2d.append({
                        'x': x_2d,
                        'y': y_2d,
                        'z': z_2d,
                        'relative_x': landmark.x,
                        'relative_y': landmark.y,
                        'relative_z': landmark.z,
                        'visibility': landmark.visibility if hasattr(landmark, 'visibility') else 1.0,
                        'presence': landmark.presence if hasattr(landmark, 'presence') else 1.0
                    })
                    
                    landmarks_3d.append({
                        'x': landmark.x,
                        'y': landmark.y,
                        'z': landmark.z
                    })
                
                result['face_landmarks_2d'].append(landmarks_2d)
                result['face_landmarks_3d'].append(landmarks_3d)
                result['landmarks'].append(landmarks_2d)
                
                if debug:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∞–∂–Ω—ã–µ landmarks
                    important_landmarks = {
                        10: '–í–µ—Ä—Ö–Ω—è—è –≥—É–±–∞ (–≤–µ—Ä—Ö)',
                        152: '–ü–æ–¥–±–æ—Ä–æ–¥–æ–∫',
                        33: '–ù–æ—Å (–∫–æ–Ω—á–∏–∫)',
                        468: '–ü—Ä–∞–≤—ã–π –≥–ª–∞–∑ (–≤–Ω–µ—à–Ω–∏–π —É–≥–æ–ª)',
                        473: '–õ–µ–≤—ã–π –≥–ª–∞–∑ (–≤–Ω–µ—à–Ω–∏–π —É–≥–æ–ª)',
                        0: '–ü—Ä–∞–≤—ã–π –≥–ª–∞–∑ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É–≥–æ–ª)',
                        227: '–õ–µ–≤—ã–π –≥–ª–∞–∑ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É–≥–æ–ª)',
                    }
                    debug_print(f"  –í–∞–∂–Ω—ã–µ landmarks:")
                    for lm_idx, desc in important_landmarks.items():
                        if lm_idx < len(landmarks_2d):
                            lm = landmarks_2d[lm_idx]
                            debug_print(f"    [{lm_idx}] {desc}: ({lm['x']}, {lm['y']}) [z={lm['z']:.2f}, vis={lm['visibility']:.3f}]")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (–≥–ª—É–±–∏–Ω–∞)
                    z_values = [lm['z'] for lm in landmarks_2d]
                    if z_values:
                        debug_print(f"  –ì–ª—É–±–∏–Ω–∞ (z): min={min(z_values):.2f}, max={max(z_values):.2f}, mean={sum(z_values)/len(z_values):.2f}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ visibility
                    vis_values = [lm['visibility'] for lm in landmarks_2d]
                    if vis_values:
                        debug_print(f"  –í–∏–¥–∏–º–æ—Å—Ç—å: min={min(vis_values):.3f}, max={max(vis_values):.3f}, mean={sum(vis_values)/len(vis_values):.3f}")
        else:
            if debug:
                debug_print("‚ùå Face Mesh –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª –ª–∏—Ü–∞")
    
    if debug:
        debug_print("\n" + "="*60)
        debug_print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
        debug_print("="*60)
        debug_print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {result['face_count']}")
        debug_print(f"Bounding boxes: {len(result['bounding_boxes'])}")
        debug_print(f"Face Mesh —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(result['face_landmarks_2d'])}")
        debug_print(f"–í—Å–µ–≥–æ landmarks: {sum(len(lm) for lm in result['landmarks'])}")
        debug_print("="*60 + "\n")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
    if debug_file and debug_output:
        try:
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(debug_output))
            if debug:
                print(f"üíæ –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {debug_file}")
        except Exception as e:
            if debug:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª: {e}")
    
    return result if result['detected'] else None


def strip_background(portrait: Image.Image, model_name: str = "isnet-general-use") -> Image.Image:
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–æ–Ω –ø–æ—Ä—Ç—Ä–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é rembg.
    
    –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
    - 'isnet-general-use' - ISNet (–ª—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤)
    - 'u2net_human_seg' - U2Net –¥–ª—è –ª—é–¥–µ–π (—Ö–æ—Ä–æ—à–æ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤)
    - 'u2net' - U2Net –±–∞–∑–æ–≤–∞—è (–±—ã—Å—Ç—Ä–∞—è, —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è)
    - 'silueta' - Silueta (—Ö–æ—Ä–æ—à–∞—è –¥–ª—è –æ–±—â–∏—Ö —Å–ª—É—á–∞–µ–≤)
    - 'u2netp' - U2Net –ª–µ–≥–∫–∞—è –≤–µ—Ä—Å–∏—è (–±—ã—Å—Ç—Ä–∞—è)
    """
    session = new_session(model_name)
    return remove(portrait, session=session)


def keep_largest_component(img: Image.Image) -> Image.Image:
    """
    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —Å–≤—è–∑–∞–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤ –º–∞—Å–∫–µ.
    –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–±—Ä–∞—Ç—å –ª—é–¥–µ–π –Ω–∞ —Ñ–æ–Ω–µ, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞.
    """
    cv_img = pil_to_cv(img)
    alpha = cv_img[:, :, 3]
    
    # –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º –º–∞—Å–∫—É (–ø–æ—Ä–æ–≥ 127 –¥–ª—è —É—á–µ—Ç–∞ –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π)
    _, binary_mask = cv2.threshold(alpha, 127, 255, cv2.THRESH_BINARY)
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
        binary_mask, connectivity=8
    )
    
    if num_labels <= 1:
        # –ù–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–ª–∏ —Ç–æ–ª—å–∫–æ —Ñ–æ–Ω
        return img
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (–∏–≥–Ω–æ—Ä–∏—Ä—É—è —Ñ–æ–Ω —Å –∏–Ω–¥–µ–∫—Å–æ–º 0)
    largest_component_idx = 1
    largest_area = stats[1, cv2.CC_STAT_AREA]
    
    for i in range(2, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area > largest_area:
            largest_area = area
            largest_component_idx = i
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É —Ç–æ–ª—å–∫–æ —Å —Å–∞–º—ã–º –±–æ–ª—å—à–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º
    largest_mask = (labels == largest_component_idx).astype(np.uint8) * 255
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –∫ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª—É (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∞–ª—å—Ñ–∞ —Ç–∞–º, –≥–¥–µ –µ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç)
    alpha = np.where(largest_mask > 0, alpha, 0).astype(np.uint8)
    
    cv_img[:, :, 3] = alpha
    return cv_to_pil(cv_img)


def refine_alpha(
    img: Image.Image,
    erode: int = 0,
    dilate: int = 0,
    feather: int = 0,
    keep_largest: bool = True,
) -> Image.Image:
    """
    –£–ª—É—á—à–∞–µ—Ç –º–∞—Å–∫—É: —ç—Ä–æ–∑–∏—è/–¥–∏–ª—è—Ç–∞—Ü–∏—è –∏ –ª—ë–≥–∫–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ –ø–æ –∫—Ä–∞—é.
    –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –ø–∏–∫—Å–µ–ª–∏ (—Ü–µ–ª—ã–µ, >=0). feather –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Gaussian blur.
    
    Args:
        keep_largest: –ï—Å–ª–∏ True, –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (—É–±–∏—Ä–∞–µ—Ç –ª—é–¥–µ–π –Ω–∞ —Ñ–æ–Ω–µ)
    """
    cv_img = pil_to_cv(img)
    alpha = cv_img[:, :, 3]

    # –°–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    if keep_largest:
        _, binary_mask = cv2.threshold(alpha, 127, 255, cv2.THRESH_BINARY)
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(
            binary_mask, connectivity=8
        )
        
        if num_labels > 1:
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (–∏–≥–Ω–æ—Ä–∏—Ä—É—è —Ñ–æ–Ω —Å –∏–Ω–¥–µ–∫—Å–æ–º 0)
            largest_component_idx = 1
            largest_area = stats[1, cv2.CC_STAT_AREA]
            
            for i in range(2, num_labels):
                area = stats[i, cv2.CC_STAT_AREA]
                if area > largest_area:
                    largest_area = area
                    largest_component_idx = i
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É —Ç–æ–ª—å–∫–æ —Å —Å–∞–º—ã–º –±–æ–ª—å—à–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º
            largest_mask = (labels == largest_component_idx).astype(np.uint8) * 255
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –∫ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª—É
            alpha = np.where(largest_mask > 0, alpha, 0).astype(np.uint8)

    if erode > 0:
        alpha = cv2.erode(alpha, np.ones((erode, erode), np.uint8), iterations=1)
    if dilate > 0:
        alpha = cv2.dilate(alpha, np.ones((dilate, dilate), np.uint8), iterations=1)
    if feather > 0:
        k = max(1, feather | 1)  # –¥–µ–ª–∞–µ–º —è–¥—Ä–æ –Ω–µ—á—ë—Ç–Ω—ã–º
        alpha = cv2.GaussianBlur(alpha, (k, k), 0)

    alpha = np.clip(alpha, 0, 255).astype("uint8")
    cv_img[:, :, 3] = alpha
    return cv_to_pil(cv_img)


def pil_to_cv(img: Image.Image) -> np.ndarray:
    """PIL (RGBA) -> OpenCV (BGRA)."""
    return cv2.cvtColor(np.array(img), cv2.COLOR_RGBA2BGRA)


def cv_to_pil(img: np.ndarray) -> Image.Image:
    """OpenCV (BGRA) -> PIL (RGBA)."""
    return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA))


def center_face_horizontally(img: Image.Image, face_info: dict | None, debug: bool = False) -> Image.Image:
    """
    –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç –ª–∏—Ü–æ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
    –°–º–µ—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–∫, —á—Ç–æ–±—ã —Ü–µ–Ω—Ç—Ä –ª–∏—Ü–∞ —Å–æ–≤–ø–∞–¥–∞–ª —Å —Ü–µ–Ω—Ç—Ä–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    
    Args:
        img: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º
        face_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª–∏—Ü–µ –æ—Ç MediaPipe (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å bounding_boxes)
        debug: –ï—Å–ª–∏ True, –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–∏
    
    Returns:
        –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ª–∏—Ü–æ–º (—Ç–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞)
    """
    if not face_info or not face_info.get('bounding_boxes'):
        if debug:
            print("‚ö†Ô∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ")
        return img
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ (—Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ) –ª–∏—Ü–æ
    bbox = face_info['bounding_boxes'][0]
    face_center_x = bbox['x'] + bbox['width'] // 2
    img_width, img_height = img.size
    img_center_x = img_width // 2
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ - –Ω–∞ —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ —Å–¥–≤–∏–Ω—É—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    offset_x = img_center_x - face_center_x
    
    if debug:
        print(f"\nüéØ –¶–ï–ù–¢–†–ò–†–û–í–ê–ù–ò–ï –õ–ò–¶–ê –ü–û –ì–û–†–ò–ó–û–ù–¢–ê–õ–ò")
        print(f"  Bounding box: x={bbox['x']}, y={bbox['y']}, w={bbox['width']}, h={bbox['height']}")
        print(f"  –¶–µ–Ω—Ç—Ä –ª–∏—Ü–∞: {face_center_x}px")
        print(f"  –¶–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_center_x}px")
        print(f"  –ù–µ–æ–±—Ö–æ–¥–∏–º–æ–µ —Å–º–µ—â–µ–Ω–∏–µ: {offset_x}px")
    
    # –ï—Å–ª–∏ –ª–∏—Ü–æ —É–∂–µ –ø–æ —Ü–µ–Ω—Ç—Ä—É (—Å –Ω–µ–±–æ–ª—å—à–æ–π –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å—é), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if abs(offset_x) < 2:
        if debug:
            print("  ‚úÖ –õ–∏—Ü–æ —É–∂–µ –ø–æ —Ü–µ–Ω—Ç—Ä—É, —Å–º–µ—â–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return img
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–π —à–∏—Ä–∏–Ω–æ–π –¥–ª—è —Å–º–µ—â–µ–Ω–∏—è
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω (–º–∏–Ω–∏–º—É–º offset_x —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã)
    padding = abs(offset_x) + 100  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å
    temp_width = img_width + padding * 2
    temp_img = Image.new("RGBA", (temp_width, img_height), (0, 0, 0, 0))
    
    # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    # –¶–µ–Ω—Ç—Ä –ª–∏—Ü–∞ –¥–æ–ª–∂–µ–Ω –æ–∫–∞–∑–∞—Ç—å—Å—è –≤ —Ü–µ–Ω—Ç—Ä–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    temp_center = temp_width // 2
    paste_x = temp_center - face_center_x
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    temp_img.paste(img, (paste_x, 0), img)
    
    # –¢–µ–ø–µ—Ä—å –æ–±—Ä–µ–∑–∞–µ–º –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —Ü–µ–Ω—Ç—Ä–∏—Ä—É—è –ª–∏—Ü–æ
    # –¶–µ–Ω—Ç—Ä –æ–±—Ä–µ–∑–∫–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ü–µ–Ω—Ç—Ä–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    crop_start_x = temp_center - img_width // 2
    crop_end_x = crop_start_x + img_width
    result = temp_img.crop((crop_start_x, 0, crop_end_x, img_height))
    
    if debug:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º –ª–∏—Ü–æ –µ—â–µ —Ä–∞–∑
        face_info_result = detect_face_mediapipe(result, debug=False)
        if face_info_result and face_info_result.get('bounding_boxes'):
            result_bbox = face_info_result['bounding_boxes'][0]
            result_face_center = result_bbox['x'] + result_bbox['width'] // 2
            result_img_center = result.size[0] // 2
            final_offset = result_img_center - result_face_center
            print(f"  ‚úÖ –õ–∏—Ü–æ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ")
            print(f"  –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ü–µ–Ω—Ç—Ä –ª–∏—Ü–∞={result_face_center}px, —Ü–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è={result_img_center}px, –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ={final_offset}px")
            if abs(final_offset) > 5:
                print(f"  ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≤—Å–µ –µ—â–µ –≤–µ–ª–∏–∫–æ!")
        else:
            print(f"  ‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–º–µ—â–µ–Ω–æ (–Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç)")
    
    return result


def expand_to_fill_width(img: Image.Image, padding: int = 0, min_scale: float = 1.12, debug: bool = False) -> Image.Image:
    """
    –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–∫, —á—Ç–æ–±—ã –≤–∏–¥–∏–º–∞—è (–Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è) —á–∞—Å—Ç—å
    –ø–æ —à–∏—Ä–∏–Ω–µ –ø–æ—á—Ç–∏ –¥–æ—Ö–æ–¥–∏–ª–∞ –¥–æ –∫—Ä–∞—ë–≤ –∫–∞–¥—Ä–∞.
    """
    if img.mode != "RGBA":
        img = img.convert("RGBA")

    img_width, img_height = img.size
    
    # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä–µ–∑ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª
    alpha = np.array(img.split()[3])
    coords = cv2.findNonZero((alpha > 0).astype(np.uint8))
    if coords is None:
        if debug:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è")
        return img

    x, y, w, h = cv2.boundingRect(coords)
    if w == 0:
        if debug:
            print("‚ö†Ô∏è –®–∏—Ä–∏–Ω–∞ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–≤–Ω–∞ 0, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ")
        return img

    if debug:
        print(f"\nüìè –ê–ù–ê–õ–ò–ó –î–õ–Ø –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–Ø")
        print(f"  –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_width} x {img_height}")
        print(f"  Bounding box –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: x={x}, y={y}, w={w}, h={h}")
        print(f"  –¢–µ–∫—É—â–∞—è —à–∏—Ä–∏–Ω–∞ –æ–±—ä–µ–∫—Ç–∞: {w}px –∏–∑ {img_width}px ({w/img_width*100:.1f}%)")

    # –¶–µ–ª–µ–≤–∞—è —à–∏—Ä–∏–Ω–∞ (–ø–æ—á—Ç–∏ –¥–æ –∫—Ä–∞—ë–≤, –Ω–µ–±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø)
    target_width = img_width - 2 * padding

    # –ú–∞—Å—à—Ç–∞–±: –º–∏–Ω–∏–º—É–º min_scale, —á—Ç–æ–±—ã —è–≤–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å
    scale_needed = target_width / w
    scale = max(scale_needed, min_scale)
    
    if debug:
        print(f"  –¶–µ–ª–µ–≤–∞—è —à–∏—Ä–∏–Ω–∞: {target_width}px (padding={padding}px)")
        print(f"  –í—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–±: {scale_needed:.3f}, –ø—Ä–∏–º–µ–Ω—è–µ–º: {scale:.3f}")

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    new_width = int(img_width * scale)
    new_height = int(img_height * scale)
    
    if debug:
        print(f"  –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º: {img_width}x{img_height} -> {new_width}x{new_height}")
    
    resized = img.resize((new_width, new_height), Image.LANCZOS)

    # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä
    result = Image.new("RGBA", (img_width, img_height), (0, 0, 0, 0))
    offset_x = (img_width - new_width) // 2
    offset_y = (img_height - new_height) // 2
    result.paste(resized, (offset_x, offset_y), resized)

    if debug:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_alpha = np.array(result.split()[3])
        result_coords = cv2.findNonZero((result_alpha > 0).astype(np.uint8))
        if result_coords is not None:
            rx, ry, rw, rh = cv2.boundingRect(result_coords)
            print(f"  ‚úÖ –ü–æ—Å–ª–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: —à–∏—Ä–∏–Ω–∞ –æ–±—ä–µ–∫—Ç–∞={rw}px –∏–∑ {img_width}px ({rw/img_width*100:.1f}%)")
            print(f"  Offset: ({offset_x}, {offset_y})")

    return result


def align_eyes_vertical(
    img: Image.Image,
    face_info: dict | None,
    target_frac: float = 1 / 3,
    debug: bool = False,
) -> Image.Image:
    """
    –°–º–µ—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –ª–∏–Ω–∏—è –≥–ª–∞–∑ –±—ã–ª–∞ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–æ–ª–µ –≤—ã—Å–æ—Ç—ã.
    target_frac=1/3 –æ–∑–Ω–∞—á–∞–µ—Ç –ª–∏–Ω–∏—è –≥–ª–∞–∑ –Ω–∞ 1/3 –æ—Ç –≤—ã—Å–æ—Ç—ã —Å–≤–µ—Ä—Ö—É.
    """
    if not face_info:
        if debug:
            print("‚ö†Ô∏è –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–∏—Ü–µ –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è")
        return img

    img_w, img_h = img.size

    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π face_mesh landmarks, –µ—Å–ª–∏ –µ—Å—Ç—å
    eye_y = None
    if face_info.get("face_landmarks_2d"):
        lms = face_info["face_landmarks_2d"][0]
        idxs = [33, 263]  # –≤–Ω–µ—à–Ω–∏–µ —É–≥–æ–ª–∫–∏ –≥–ª–∞–∑
        vals = [lms[i]["y"] for i in idxs if i < len(lms)]
        if vals:
            eye_y = sum(vals) / len(vals)

    # –§–æ–ª–±–µ–∫: –ø–æ bounding box
    if eye_y is None and face_info.get("bounding_boxes"):
        bbox = face_info["bounding_boxes"][0]
        eye_y = bbox["y"] + bbox["height"] * 0.35

    if eye_y is None:
        if debug:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –ª–∏–Ω–∏—é –≥–ª–∞–∑, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ")
        return img

    target_y = img_h * target_frac
    offset_y = target_y - eye_y

    if debug:
        print("\nüìê –í–´–†–ê–í–ù–ò–í–ê–ù–ò–ï –ü–û –í–ï–†–¢–ò–ö–ê–õ–ò (–≥–ª–∞–∑–∞ –Ω–∞ 1/3)")
        print(f"  Eye Y: {eye_y:.1f}px, Target Y: {target_y:.1f}px")
        print(f"  –°–º–µ—â–µ–Ω–∏–µ: {offset_y:.1f}px")

    if abs(offset_y) < 1:
        if debug:
            print("  ‚úÖ –°–º–µ—â–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return img

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∑–∞–ø–∞—Å–æ–º –ø–æ –≤—ã—Å–æ—Ç–µ
    padding = int(abs(offset_y)) + 100
    temp_h = img_h + padding * 2
    temp_w = img_w
    temp = Image.new("RGBA", (temp_w, temp_h), (0, 0, 0, 0))

    # –í—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ–∑–∏—Ü–∏—é, –≥–¥–µ –≥–ª–∞–∑–∞ –±—É–¥—É—Ç –Ω–∞ target_y
    # target_y –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    temp_target_y = target_y + padding  # –î–æ–±–∞–≤–ª—è–µ–º padding —Å–≤–µ—Ä—Ö—É
    paste_y = int(temp_target_y - eye_y)
    temp.paste(img, (0, paste_y), img)

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–π –≤—ã—Å–æ—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –≥–ª–∞–∑–∞ –Ω–∞ target_y
    # –û–±—Ä–µ–∑–∞–µ–º —Ç–∞–∫, —á—Ç–æ–±—ã target_y –æ—Å—Ç–∞–ª—Å—è –Ω–∞ —Ç–æ–π –∂–µ –ø–æ–∑–∏—Ü–∏–∏
    crop_start_y = padding
    crop_end_y = crop_start_y + img_h
    result = temp.crop((0, crop_start_y, img_w, crop_end_y))

    if debug:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ —Å–¥–≤–∏–≥–∞
        face_info_check = detect_face_mediapipe(result, debug=False)
        if face_info_check and face_info_check.get("face_landmarks_2d"):
            lms2 = face_info_check["face_landmarks_2d"][0]
            vals2 = [lms2[i]["y"] for i in [33, 263] if i < len(lms2)]
            if vals2:
                new_eye_y = sum(vals2) / len(vals2)
                print(f"  ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞: eye_y={new_eye_y:.1f}px, —Ü–µ–ª—å={target_y:.1f}px, –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ={(target_y - new_eye_y):.1f}px")

    return result


def fill_bottom_gap_with_last_pixels(img: Image.Image, debug: bool = False) -> Image.Image:
    """
    –†–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç –Ω–∏–∂–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏ –¥–æ –Ω–∏–∑–∞, –µ—Å–ª–∏ —Å–Ω–∏–∑—É –µ—Å—Ç—å –ø—É—Å—Ç–æ—Ç–∞ (–ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å).
    """
    if img.mode != "RGBA":
        img = img.convert("RGBA")

    alpha = np.array(img.split()[3])
    coords = cv2.findNonZero((alpha > 0).astype(np.uint8))
    if coords is None:
        return img

    x, y, w, h = cv2.boundingRect(coords)
    img_w, img_h = img.size
    bottom = y + h
    gap = img_h - bottom
    if gap <= 0:
        return img

    # –ë–µ—Ä–µ–º –Ω–∏–∂–Ω—é—é –ø–æ–ª–æ—Å–∫—É –∏ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ–º
    strip_h = min(4, h) if h > 0 else 1
    strip_top = max(bottom - strip_h, 0)
    strip = img.crop((0, strip_top, img_w, bottom))
    stretched = strip.resize((img_w, gap + strip_h), Image.BILINEAR)

    result = img.copy()
    paste_y = strip_top
    result.paste(stretched, (0, paste_y), stretched)

    if debug:
        print(f"üîª –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–∏–∑–∞: gap={gap}px, strip_h={strip_h}px, paste_y={paste_y}")

    return result


def fit_to_size(
    img: Image.Image,
    target_size: tuple[int, int],
    anchor_y: float = 0.5,
) -> Image.Image:
    """
    –í–ø–∏—Å—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π.
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.
    anchor_y ‚Äî –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ø—Ä–∏–≤—è–∑–∫–∞ (0=—Å–≤–µ—Ä—Ö—É, 0.5=—Ü–µ–Ω—Ç—Ä, 1=—Å–Ω–∏–∑—É).
    """
    target_width, target_height = target_size
    img_width, img_height = img.size
    
    scale = min(target_width / img_width, target_height / img_height)
    new_width = int(img_width * scale)
    new_height = int(img_height * scale)
    
    resized = img.resize((new_width, new_height), Image.LANCZOS)
    
    result = Image.new("RGBA", (target_width, target_height), (0, 0, 0, 0))
    
    x_offset = (target_width - new_width) // 2
    y_space = target_height - new_height
    y_offset = int(y_space * anchor_y)
    y_offset = max(0, min(y_offset, target_height - new_height))
    
    result.paste(resized, (x_offset, y_offset), resized)
    
    return result


def reinhard_color_transfer(
    source_bgr: np.ndarray, target_bgr: np.ndarray, mask: np.ndarray | None = None
) -> np.ndarray:
    """
    –ü–µ—Ä–µ–Ω–æ—Å —Ü–≤–µ—Ç–∞ –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ –†–µ–π–Ω—Ö–∞—Ä–¥–∞ (Lab).
    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ –º–∞—Å–∫–∞ (uint8 0/255), —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ –Ω–µ–π,
    –∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏.
    """
    source_lab = cv2.cvtColor(source_bgr, cv2.COLOR_BGR2LAB).astype("float32")
    target_lab = cv2.cvtColor(target_bgr, cv2.COLOR_BGR2LAB).astype("float32")

    if mask is None:
        mask = np.full(source_lab.shape[:2], 255, dtype=np.uint8)

    # –°—Ä–µ–¥–Ω–∏–µ –∏ —Å–∏–≥–º—ã –ø–æ –º–∞—Å–∫–µ
    (l_mean_src, a_mean_src, b_mean_src), (l_std_src, a_std_src, b_std_src) = (
        cv2.meanStdDev(source_lab, mask=mask)
    )
    (l_mean_tgt, a_mean_tgt, b_mean_tgt), (l_std_tgt, a_std_tgt, b_std_tgt) = (
        cv2.meanStdDev(target_lab)
    )

    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å
    l_std_src = l_std_src + 1e-6
    a_std_src = a_std_src + 1e-6
    b_std_src = b_std_src + 1e-6

    result_lab = source_lab.copy()
    m = mask > 0

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ –º–∞—Å–∫–∏
    for channel_idx, (mean_src, std_src, mean_tgt, std_tgt) in enumerate(
        [
            (l_mean_src, l_std_src, l_mean_tgt, l_std_tgt),
            (a_mean_src, a_std_src, a_mean_tgt, a_std_tgt),
            (b_mean_src, b_std_src, b_mean_tgt, b_std_tgt),
        ]
    ):
        channel = result_lab[:, :, channel_idx]
        channel[m] = (
            (channel[m] - mean_src[0]) * (std_tgt[0] / std_src[0]) + mean_tgt[0]
        )

    result_lab = np.clip(result_lab, 0, 255).astype("uint8")
    return cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)


def apply_color_reference(
    portrait_rgba: Image.Image,
    ref_image: Image.Image,
    color_strength: float = 1.0,
    reduce_contrast: float = 0.85,
    brightness_adjust: float = 0.0,
    saturation_adjust: float = 0.0,
) -> Image.Image:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –ø–æ—Ä—Ç—Ä–µ—Ç –∫ —Ü–≤–µ—Ç–∞–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª.
    
    Args:
        portrait_rgba: –ü–æ—Ä—Ç—Ä–µ—Ç —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º
        ref_image: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        color_strength: –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å–∞ —Ü–≤–µ—Ç–∞ (0.0-1.0, –≥–¥–µ 1.0 = –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å, 0.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        reduce_contrast: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–Ω–∏–∂–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (0.0-1.0, –≥–¥–µ 1.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, 0.85 = —Å–Ω–∏–∂–µ–Ω–∏–µ –Ω–∞ 15%)
        brightness_adjust: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏ (-1.0 –¥–æ 1.0, –≥–¥–µ 0.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ = —è—Ä—á–µ)
        saturation_adjust: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ (-1.0 –¥–æ 1.0, –≥–¥–µ 0.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ = –Ω–∞—Å—ã—â–µ–Ω–Ω–µ–µ)
    """
    portrait_cv = pil_to_cv(portrait_rgba)
    ref_cv = pil_to_cv(ref_image)

    alpha = portrait_cv[:, :, 3]
    mask = (alpha > 0).astype(np.uint8) * 255

    # –¶–≤–µ—Ç–∞ —Ç–æ–ª—å–∫–æ –∏–∑ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–æ–π —á–∞—Å—Ç–∏
    source_bgr = portrait_cv[:, :, :3]
    target_bgr = ref_cv[:, :, :3]

    if mask.sum() == 0:
        return portrait_rgba

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Ü–≤–µ—Ç–∞ —Å —É—á–µ—Ç–æ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
    if color_strength > 0:
        transferred_bgr = reinhard_color_transfer(source_bgr, target_bgr, mask=mask)
        if color_strength < 1.0:
            # –°–º–µ—à–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            transferred_bgr = cv2.addWeighted(
                source_bgr, 1.0 - color_strength, transferred_bgr, color_strength, 0
            )
    else:
        transferred_bgr = source_bgr.copy()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ LAB –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —è—Ä–∫–æ—Å—Ç—å—é –∏ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å—é
    lab = cv2.cvtColor(transferred_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)
    
    # –°–Ω–∏–∂–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –¥–ª—è –±–æ–ª–µ–µ –º—è–≥–∫–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if reduce_contrast < 1.0:
        l_channel = lab[:, :, 0]
        mean_l = l_channel[mask > 0].mean() if mask.sum() > 0 else l_channel.mean()
        l_channel = l_channel * reduce_contrast + mean_l * (1 - reduce_contrast)
        lab[:, :, 0] = np.clip(l_channel, 0, 255)
    
    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏
    if brightness_adjust != 0.0:
        l_channel = lab[:, :, 0]
        adjustment = brightness_adjust * 50  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        l_channel = np.clip(l_channel + adjustment, 0, 255)
        lab[:, :, 0] = l_channel
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ BGR
    transferred_bgr = cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
    
    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ (—Ä–∞–±–æ—Ç–∞–µ–º –≤ HSV)
    if saturation_adjust != 0.0:
        hsv = cv2.cvtColor(transferred_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)
        s_channel = hsv[:, :, 1]
        adjustment = saturation_adjust * 100  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        s_channel = np.clip(s_channel + adjustment, 0, 255)
        hsv[:, :, 1] = s_channel
        transferred_bgr = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
    
    portrait_cv[:, :, :3] = transferred_bgr
    return cv_to_pil(portrait_cv)


def apply_sepia(img: Image.Image, strength: float = 1.0) -> Image.Image:
    """
    –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç —Å–µ–ø–∏—é (–∫–æ—Ä–∏—á–Ω–µ–≤–∞—Ç—ã–π –æ—Ç—Ç–µ–Ω–æ–∫) –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
    
    Args:
        img: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º
        strength: –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∞ —Å–µ–ø–∏–∏ (0.0-1.0, –≥–¥–µ 1.0 = –ø–æ–ª–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç)
    
    Returns:
        –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —ç—Ñ—Ñ–µ–∫—Ç–æ–º —Å–µ–ø–∏–∏
    """
    if strength <= 0:
        return img
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if img.mode == "RGBA":
        rgb_img = img.convert("RGB")
        has_alpha = True
        alpha = img.split()[3]
    else:
        rgb_img = img.convert("RGB")
        has_alpha = False
    
    # –ú–∞—Ç—Ä–∏—Ü–∞ —Å–µ–ø–∏–∏ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è)
    sepia_matrix = np.array([
        [0.393, 0.769, 0.189],
        [0.349, 0.686, 0.168],
        [0.272, 0.534, 0.131]
    ])
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å–µ–ø–∏–∏
    img_array = np.array(rgb_img).astype(np.float32)
    sepia_array = img_array @ sepia_matrix.T
    sepia_array = np.clip(sepia_array, 0, 255).astype(np.uint8)
    
    # –°–º–µ—à–∏–≤–∞–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç strength
    if strength < 1.0:
        sepia_array = (img_array * (1 - strength) + sepia_array * strength).astype(np.uint8)
    
    result = Image.fromarray(sepia_array, mode="RGB")
    
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª, –µ—Å–ª–∏ –±—ã–ª
    if has_alpha:
        result = result.convert("RGBA")
        result.putalpha(alpha)
    
    return result


def enhance_face_gfpgan(
    img_rgba: Image.Image, upscale: int = 1, strength: float = 1.0, iterations: int = 1
) -> Image.Image:
    """
    –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ/—É–ª—É—á—à–µ–Ω–∏–µ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ GFPGAN (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω).
    
    Args:
        img_rgba: –í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º
        upscale: –ú–∞—Å—à—Ç–∞–± —É–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (1-4, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 2-4)
        strength: –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∞ (0.0-1.0, –≥–¥–µ 1.0 = –ø–æ–ª–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç)
        iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π —É–ª—É—á—à–µ–Ω–∏—è (1-3, –±–æ–ª—å—à–µ = —Å–∏–ª—å–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç)
    """
    # –®–∏–º: –≤ –Ω–æ–≤—ã—Ö torchvision –º–æ–¥—É–ª—å functional_tensor –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, basicsr –µ–≥–æ –∂–¥–µ—Ç.
    try:
        import torchvision.transforms.functional_tensor as _  # type: ignore
    except ImportError:
        from torchvision.transforms import functional as F

        ft_module = types.ModuleType("torchvision.transforms.functional_tensor")
        ft_module.rgb_to_grayscale = F.rgb_to_grayscale
        sys.modules["torchvision.transforms.functional_tensor"] = ft_module

    try:
        from gfpgan import GFPGANer
    except ImportError as exc:  # pragma: no cover - –≤–Ω–µ—à–Ω—è—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
        raise RuntimeError(
            "GFPGAN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install gfpgan"
        ) from exc

    cv_img = pil_to_cv(img_rgba)
    alpha = cv_img[:, :, 3]
    bgr = cv_img[:, :, :3]
    original_bgr = bgr.copy()

    restorer = GFPGANer(
        model_path="https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth",
        upscale=upscale,
        arch="clean",
        channel_multiplier=2,
        bg_upsampler=None,
    )

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
    restored_bgr = bgr.copy()
    for _ in range(iterations):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: cropped_faces, restored_faces, restored_img
        _, _, restored_bgr = restorer.enhance(
            restored_bgr, has_aligned=False, only_center_face=False, paste_back=True
        )
        
        # GFPGAN –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å —Ä–∞–∑–º–µ—Ä (upscale>1). –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É.
        if restored_bgr.shape[:2] != original_bgr.shape[:2]:
            restored_bgr = cv2.resize(
                restored_bgr,
                (original_bgr.shape[1], original_bgr.shape[0]),
                interpolation=cv2.INTER_LINEAR,
            )

    # –°–º–µ—à–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç strength
    if strength < 1.0:
        restored_bgr = cv2.addWeighted(
            original_bgr, 1.0 - strength, restored_bgr, strength, 0
        )

    cv_img[:, :, :3] = restored_bgr
    cv_img[:, :, 3] = alpha
    return cv_to_pil(cv_img)


def process(
    portrait_path: str,
    ref_path: str,
    output_path: str,
    use_face_enhance: bool = True,
    face_upscale: int = 4,
    face_strength: float = 0.7,
    face_iterations: int = 2,
    background_path: str | None = None,
    alpha_erode: int = 17,
    alpha_dilate: int = 0,
    alpha_feather: int = 16,
    bg_model: str = "u2net_human_seg",
    keep_largest: bool = True,
    face_detect: bool = True,
    center_face: bool = False,
    normalize_exposure: bool = False,
    color_strength: float = 1.0,
    reduce_contrast: float = 0.85,
    brightness_adjust: float = 0.0,
    saturation_adjust: float = 0.0,
    sepia_strength: float = 0.0,
) -> float:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—Ç—Ä–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö.
    """
    start_time = time.time()
    
    portrait = load_image(portrait_path, debug_orientation=face_detect)
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–∫—Å–ø–æ–∑–∏—Ü–∏—é –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if normalize_exposure:
        portrait = normalize_exposure(portrait, debug=face_detect)
    ref = load_image(ref_path)

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ —Å –ø–æ–º–æ—â—å—é MediaPipe (–¥–ª—è –¥–µ–±–∞–≥–∞ –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è)
    face_info = None
    if face_detect:
        print("\n" + "üîç" * 30)
        print("–ù–ê–ß–ê–õ–û –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –õ–ò–¶–ê –° MEDIAPIPE")
        print("üîç" * 30)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª —Ä—è–¥–æ–º —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        debug_file_path = output_path.replace('.png', '_mediapipe_debug.txt').replace('.jpg', '_mediapipe_debug.txt')
        face_info = detect_face_mediapipe(portrait, debug=True, debug_file=debug_file_path)
        if face_info:
            print("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            print(f"üíæ –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {debug_file_path}")
        else:
            print("‚ö†Ô∏è –õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–ª–∏ MediaPipe –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üîç" * 30 + "\n")

    portrait_no_bg = strip_background(portrait, model_name=bg_model)
    portrait_no_bg = refine_alpha(
        portrait_no_bg,
        erode=alpha_erode,
        dilate=alpha_dilate,
        feather=alpha_feather,
        keep_largest=keep_largest,  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
    )
    
    # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ª–∏—Ü–æ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if center_face:
        # –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ª–∏—Ü–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ —Ñ–æ–Ω–∞
        face_info_no_bg = detect_face_mediapipe(portrait_no_bg, debug=False)
        if face_info_no_bg:
            if face_detect:
                print("\nüéØ –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –¶–ï–ù–¢–†–ò–†–û–í–ê–ù–ò–Ø –õ–ò–¶–ê")
            portrait_no_bg = center_face_horizontally(portrait_no_bg, face_info_no_bg, debug=face_detect)
            # –ü–æ—Å–ª–µ —Å–¥–≤–∏–≥–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –¥–æ—Ö–æ–¥–∏–ª–∞ –¥–æ –∫—Ä–∞—ë–≤
            portrait_no_bg = expand_to_fill_width(portrait_no_bg, padding=0, min_scale=1.12, debug=face_detect)
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ –æ –ª–∏—Ü–µ –ø–æ—Å–ª–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            face_info_scaled = detect_face_mediapipe(portrait_no_bg, debug=False)
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏: –ª–∏–Ω–∏—è –≥–ª–∞–∑ –Ω–∞ 1/3 –≤—ã—Å–æ—Ç—ã
            portrait_no_bg = align_eyes_vertical(portrait_no_bg, face_info_scaled or face_info_no_bg, target_frac=1/3, debug=face_detect)
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–∏–∑ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ–º –Ω–∏–∂–Ω–∏—Ö –ø–∏–∫—Å–µ–ª–µ–π, —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –ø—É—Å—Ç–æ—Ç—É
            portrait_no_bg = fill_bottom_gap_with_last_pixels(portrait_no_bg, debug=face_detect)
            if face_detect:
                print("üéØ" * 30 + "\n")
    elif face_detect:
        print("\n‚ö†Ô∏è –õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –±–µ–∑ —Ñ–æ–Ω–∞, —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ\n")
    colored = apply_color_reference(
        portrait_no_bg,
        ref,
        color_strength=color_strength,
        reduce_contrast=reduce_contrast,
        brightness_adjust=brightness_adjust,
        saturation_adjust=saturation_adjust,
    )
    if use_face_enhance:
        colored = enhance_face_gfpgan(
            colored,
            upscale=face_upscale,
            strength=face_strength,
            iterations=face_iterations,
        )

    if background_path and os.path.exists(background_path):
        bg = Image.open(background_path).convert("RGBA")
        bg_resized = bg.resize(colored.size, Image.LANCZOS)
        # –ö–ª–∞–¥—ë–º –ø–æ—Ä—Ç—Ä–µ—Ç —Å–≤–µ—Ä—Ö—É (—Å –∞–ª—å—Ñ–æ–π) –Ω–∞ —Ñ–æ–Ω
        colored = Image.alpha_composite(bg_resized, colored)

    # –í–ø–∏—Å—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ä–∞–∑–º–µ—Ä 720x1280 —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
    # anchor_y=1/3 —á—Ç–æ–±—ã –ª–∏–Ω–∏—è –≥–ª–∞–∑ –æ—Å—Ç–∞–ª–∞—Å—å –±–ª–∏–∂–µ –∫ –≤–µ—Ä—Ö–Ω–µ–π —Ç—Ä–µ—Ç–∏
    colored = fit_to_size(colored, (720, 1280), anchor_y=1/3)
    
    # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Å–µ–ø–∏—é (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if sepia_strength > 0:
        colored = apply_sepia(colored, strength=sepia_strength)

    colored.save(output_path)
    
    elapsed_time = time.time() - start_time
    return elapsed_time


def main() -> None:
    parser = argparse.ArgumentParser(
        description="–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Ü–≤–µ—Ç–∞–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞."
    )
    parser.add_argument("portrait", help="–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—Ç—Ä–µ—Ç—É")
    parser.add_argument(
        "reference",
        nargs="?",
        default="src/ref.png",
        help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—É –ø–æ —Ü–≤–µ—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: src/ref.png)",
    )
    parser.add_argument(
        "-o",
        "--output",
        default="result.png",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (PNG —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º)",
    )
    parser.add_argument(
        "--face-enhance",
        action="store_true",
        help="–°–≥–ª–∞–¥–∏—Ç—å/—É–ª—É—á—à–∏—Ç—å –ª–∏—Ü–æ —á–µ—Ä–µ–∑ GFPGAN (—Ç—Ä–µ–±—É–µ—Ç—Å—è pip install gfpgan). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --no-face-enhance –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--no-face-enhance",
        action="store_false",
        dest="face_enhance",
        help="–û—Ç–∫–ª—é—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –ª–∏—Ü–∞",
    )
    parser.add_argument(
        "--face-upscale",
        type=int,
        default=4,
        help="–ú–∞—Å—à—Ç–∞–± —É–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–ª—è GFPGAN (1-4, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 2-4, –≤—ã—à–µ = –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏)",
    )
    parser.add_argument(
        "--face-strength",
        type=float,
        default=0.7,
        help="–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –ª–∏—Ü–∞ (0.0-1.0, –≥–¥–µ 1.0 = –ø–æ–ª–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)",
    )
    parser.add_argument(
        "--face-iterations",
        type=int,
        default=2,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π —É–ª—É—á—à–µ–Ω–∏—è (1-3, –±–æ–ª—å—à–µ = —Å–∏–ª—å–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2)",
    )
    parser.add_argument(
        "--background",
        default="src/bg.jpg",
        help="–ü—É—Ç—å –∫ —Ñ–æ–Ω—É (RGBA/RGB). –ë—É–¥–µ—Ç –ø–æ–¥–ª–æ–∂–µ–Ω –ø–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: src/bg.jpg). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --no-background –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--no-background",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ–Ω (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç --background)",
    )
    parser.add_argument(
        "--alpha-erode",
        type=int,
        default=17,
        help="–°–∂–∞—Ç—å –º–∞—Å–∫—É –Ω–∞ N –ø–∏–∫—Å–µ–ª–µ–π (—ç—Ä–æ–∑–∏—è) –¥–ª—è —É–±–æ—Ä–∫–∏ –æ—Ä–µ–æ–ª–æ–≤",
    )
    parser.add_argument(
        "--alpha-dilate",
        type=int,
        default=0,
        help="–†–∞—Å—à–∏—Ä–∏—Ç—å –º–∞—Å–∫—É –Ω–∞ N –ø–∏–∫—Å–µ–ª–µ–π (–¥–∏–ª—è—Ç–∞—Ü–∏—è) –ø–æ—Å–ª–µ —ç—Ä–æ–∑–∏–∏",
    )
    parser.add_argument(
        "--alpha-feather",
        type=int,
        default=16,
        help="–†–∞–∑–º—ã—Ç–∏–µ –∫—Ä–∞—è –º–∞—Å–∫–∏ (Gaussian blur, –ø–∏–∫—Å–µ–ª–∏) –¥–ª—è –º—è–≥–∫–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞",
    )
    parser.add_argument(
        "--bg-model",
        type=str,
        default="u2net_human_seg",
        choices=["isnet-general-use", "u2net_human_seg", "u2net", "silueta", "u2netp"],
        help="–ú–æ–¥–µ–ª—å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞: u2net_human_seg (–¥–ª—è –ª—é–¥–µ–π, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), isnet-general-use (–ª—É—á—à–∞—è), u2net (–±–∞–∑–æ–≤–∞—è), silueta, u2netp (–ª–µ–≥–∫–∞—è)",
    )
    parser.add_argument(
        "--keep-all",
        action="store_true",
        help="–û—Å—Ç–∞–≤–∏—Ç—å –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –º–∞—Å–∫–µ (–Ω–µ —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –æ–±—ä–µ–∫—Ç.",
    )
    parser.add_argument(
        "--preset",
        choices=["face3", "face8"],
        help="–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏: face3 (upscale=3, —Ñ–æ–Ω bg.jpg), face8 (upscale=8, —Ñ–æ–Ω bg.jpg)",
    )
    parser.add_argument(
        "--face-detect",
        action="store_true",
        default=True,
        help="–í–∫–ª—é—á–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ —Å –ø–æ–º–æ—â—å—é MediaPipe –¥–ª—è –¥–µ–±–∞–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–æ)",
    )
    parser.add_argument(
        "--no-face-detect",
        action="store_false",
        dest="face_detect",
        help="–û—Ç–∫–ª—é—á–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ —Å –ø–æ–º–æ—â—å—é MediaPipe",
    )
    parser.add_argument(
        "--center-face",
        action="store_true",
        default=False,
        help="–í–∫–ª—é—á–∏—Ç—å —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–∫–ª—é—á–µ–Ω–æ)",
    )
    parser.add_argument(
        "--normalize-exposure",
        action="store_true",
        default=False,
        help="–í–∫–ª—é—á–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —ç–∫—Å–ø–æ–∑–∏—Ü–∏–∏ (—É–≤–µ–ª–∏—á–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏) –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–∫–ª—é—á–µ–Ω–æ)",
    )
    parser.add_argument(
        "--color-strength",
        type=float,
        default=1.0,
        help="–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å–∞ —Ü–≤–µ—Ç–∞ –∏–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ (0.0-1.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0 = –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å)",
    )
    parser.add_argument(
        "--reduce-contrast",
        type=float,
        default=0.85,
        help="–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–Ω–∏–∂–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Ü–≤–µ—Ç–∞ (0.0-1.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.85)",
    )
    parser.add_argument(
        "--brightness-adjust",
        type=float,
        default=0.0,
        help="–ö–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏ (-1.0 –¥–æ 1.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)",
    )
    parser.add_argument(
        "--saturation-adjust",
        type=float,
        default=0.0,
        help="–ö–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ (-1.0 –¥–æ 1.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)",
    )
    parser.add_argument(
        "--sepia",
        type=float,
        default=0.0,
        help="–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∞ —Å–µ–ø–∏–∏ (0.0-1.0, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.0 = –æ—Ç–∫–ª—é—á–µ–Ω–æ)",
    )
    args = parser.parse_args()

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if not hasattr(args, 'face_enhance') or args.face_enhance is None:
        args.face_enhance = True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if not os.path.exists(args.reference):
        raise FileNotFoundError(f"–†–µ—Ñ–µ—Ä–µ–Ω—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.reference}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–æ–Ω
    if args.no_background:
        args.background = None
    elif args.background == "src/bg.jpg" and not os.path.exists("src/bg.jpg"):
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ–Ω
        args.background = None
    elif args.background and not os.path.exists(args.background):
        raise FileNotFoundError(f"–§–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.background}")

    # –ü—Ä–µ—Å–µ—Ç—ã: –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –∫–ª—é—á–µ–≤—ã–µ –æ–ø—Ü–∏–∏, –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—è—Ç—å —Ä—É–∫–∞–º–∏.
    if args.preset:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ bg.jpg –≤ src/ –∏–ª–∏ –≤ –∫–æ—Ä–Ω–µ
        bg_path = "src/bg.jpg" if os.path.exists("src/bg.jpg") else "bg.jpg"
        preset_map = {
            "face3": {
                "face_enhance": True,
                "face_upscale": 3,
                "face_strength": 1.0,
                "face_iterations": 1,
                "background": bg_path,
            },
            "face8": {
                "face_enhance": True,
                "face_upscale": 4,
                "face_strength": 1.0,
                "face_iterations": 2,
                "background": bg_path,
            },
        }
        preset = preset_map[args.preset]
        args.face_enhance = preset["face_enhance"]
        args.face_upscale = preset["face_upscale"]
        args.face_strength = preset["face_strength"]
        args.face_iterations = preset["face_iterations"]
        if args.background is None:
            args.background = preset["background"]

    process(
        args.portrait,
        args.reference,
        args.output,
        use_face_enhance=args.face_enhance,
        face_upscale=args.face_upscale,
        face_strength=args.face_strength,
        face_iterations=args.face_iterations,
        background_path=args.background,
        alpha_erode=args.alpha_erode,
        alpha_dilate=args.alpha_dilate,
        alpha_feather=args.alpha_feather,
        bg_model=args.bg_model,
        keep_largest=not args.keep_all,  # –ï—Å–ª–∏ --keep-all, —Ç–æ keep_largest=False
        face_detect=args.face_detect,
        center_face=args.center_face,
        normalize_exposure=args.normalize_exposure,
        color_strength=args.color_strength,
        reduce_contrast=args.reduce_contrast,
        brightness_adjust=args.brightness_adjust,
        saturation_adjust=args.saturation_adjust,
        sepia_strength=args.sepia,
    )


if __name__ == "__main__":
    main()

